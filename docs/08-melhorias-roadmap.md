# Melhorias e Roadmap do AMLDO

## ğŸ“‹ SumÃ¡rio

- [VisÃ£o de Produto](#visÃ£o-de-produto)
- [Melhorias Propostas](#melhorias-propostas)
- [Roadmap](#roadmap)
- [Ideias Futuras](#ideias-futuras)
- [CritÃ©rios de PriorizaÃ§Ã£o](#critÃ©rios-de-priorizaÃ§Ã£o)

## VisÃ£o de Produto

### Onde Estamos (v1.0)

âœ… Sistema RAG funcional para consultas sobre legislaÃ§Ã£o
âœ… Interface web bÃ¡sica
âœ… 4 documentos legais indexados
âœ… Respostas fundamentadas e precisas

### Onde Queremos Chegar (v2.0)

ğŸ¯ **VisÃ£o:** Ser a ferramenta de referÃªncia para profissionais de licitaÃ§Ãµes e compliance consultarem legislaÃ§Ã£o brasileira.

**Objetivos:**
- ğŸ”¹ **Cobertura:** 50+ documentos legais (leis, decretos, INs, jurisprudÃªncia)
- ğŸ”¹ **Qualidade:** >95% de precisÃ£o nas respostas
- ğŸ”¹ **Performance:** <2s de latÃªncia mÃ©dia
- ğŸ”¹ **Usabilidade:** Interface intuitiva e rÃ¡pida
- ğŸ”¹ **Confiabilidade:** 99.9% uptime em produÃ§Ã£o
- ğŸ”¹ **SeguranÃ§a:** AutenticaÃ§Ã£o, auditoria, LGPD compliance

### Proposta de Valor

| Stakeholder | Valor Entregue |
|-------------|----------------|
| **Gestores PÃºblicos** | Economia de 80% do tempo em consultas legais |
| **Advogados** | CitaÃ§Ãµes precisas e rÃ¡pidas para pareceres |
| **Auditores** | FundamentaÃ§Ã£o sÃ³lida para relatÃ³rios |
| **Consultorias** | Ferramenta diferenciada para clientes |
| **Ã“rgÃ£os PÃºblicos** | ReduÃ§Ã£o de riscos e melhor compliance |

## Melhorias Propostas

### ğŸ”´ Prioridade Alta (CrÃ­ticas)

#### 1. Implementar Testes Automatizados

**Problema:** Sem testes, nÃ£o hÃ¡ garantia de qualidade

**Proposta:**
- **Testes UnitÃ¡rios** (rag_v1, rag_v2)
  ```python
  def test_consultar_base_rag():
      resposta = consultar_base_rag("Qual o limite de dispensa?")
      assert "50.000" in resposta or "cinquenta mil" in resposta.lower()
  ```

- **Testes de IntegraÃ§Ã£o** (pipeline completo)
  ```python
  def test_pipeline_completo():
      # Query â†’ Retrieval â†’ LLM â†’ Response
      assert pipeline_funciona()
  ```

- **Testes de RegressÃ£o** (gold dataset)
  ```python
  # 50 perguntas com respostas esperadas
  # Comparar saÃ­da atual vs. esperada
  # Alertar se accuracy < 90%
  ```

**Estimativa:** 2-3 semanas
**Impacto:** ğŸ”´ CrÃ­tico (reduz bugs, facilita refatoraÃ§Ã£o)

#### 2. Adicionar Logging Estruturado

**Problema:** Sem logs, impossÃ­vel debugar produÃ§Ã£o

**Proposta:**
```python
import logging
from pythonjsonlogger import jsonlogger

logger = logging.getLogger()
handler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter()
handler.setFormatter(formatter)
logger.addHandler(handler)

# Uso
logger.info("Query recebida", extra={
    "query": query,
    "user_id": user_id,
    "timestamp": time.time()
})

logger.info("Resposta gerada", extra={
    "query": query,
    "latency_ms": latency,
    "num_docs_retrieved": len(docs),
    "llm_tokens": tokens
})
```

**Campos importantes:**
- Query texto
- User ID
- Timestamp
- LatÃªncia
- Documentos recuperados
- Tokens usados (custo)
- Erros (se houver)

**Estimativa:** 1 semana
**Impacto:** ğŸ”´ CrÃ­tico (visibilidade, debugging)

#### 3. Implementar AutenticaÃ§Ã£o

**Problema:** Sistema aberto, sem controle de acesso

**Proposta (MVP):**
- **AutenticaÃ§Ã£o bÃ¡sica** (usuÃ¡rio/senha)
- **SessÃµes isoladas** por usuÃ¡rio
- **Rate limiting** (ex: 100 queries/dia por usuÃ¡rio)

**OpÃ§Ãµes:**
- **Simples:** HTTP Basic Auth
- **IntermediÃ¡rio:** JWT tokens
- **AvanÃ§ado:** OAuth 2.0 (Google, Microsoft)

**ImplementaÃ§Ã£o exemplo (FastAPI):**
```python
from fastapi import FastAPI, Depends, HTTPException
from fastapi.security import HTTPBasic, HTTPBasicCredentials

app = FastAPI()
security = HTTPBasic()

users = {
    "ana.silva": "senha123",  # Usar hash em produÃ§Ã£o!
    "carlos.mendes": "senha456"
}

def authenticate(credentials: HTTPBasicCredentials = Depends(security)):
    if credentials.username not in users:
        raise HTTPException(status_code=401)
    if users[credentials.username] != credentials.password:
        raise HTTPException(status_code=401)
    return credentials.username

@app.post("/query")
def query(text: str, user: str = Depends(authenticate)):
    # user estÃ¡ autenticado
    resposta = consultar_base_rag(text)
    return {"resposta": resposta}
```

**Estimativa:** 1-2 semanas
**Impacto:** ğŸ”´ CrÃ­tico (seguranÃ§a)

### ğŸŸ¡ Prioridade MÃ©dia (Importantes)

#### 4. Adicionar Cache de Respostas

**Problema:** Mesma pergunta = nova chamada ao LLM (caro e lento)

**Proposta:**
```python
import hashlib
import redis

# Conectar ao Redis
cache = redis.Redis(host='localhost', port=6379, db=0)

def consultar_base_rag_com_cache(pergunta: str) -> str:
    # Hash da pergunta
    query_hash = hashlib.md5(pergunta.encode()).hexdigest()

    # Verificar cache
    cached = cache.get(query_hash)
    if cached:
        logger.info("Cache hit", extra={"query_hash": query_hash})
        return cached.decode()

    # Cache miss, executar RAG
    resposta = _rag_answer(pergunta)

    # Salvar no cache (TTL: 24h)
    cache.setex(query_hash, 86400, resposta)

    return resposta
```

**BenefÃ­cios:**
- âš¡ LatÃªncia: ~5s â†’ ~0.1s (50x mais rÃ¡pido)
- ğŸ’° Custo: $0.01/query â†’ $0.00 (cache hit)

**Trade-off:**
- Infraestrutura adicional (Redis)
- Cache pode ficar stale (soluÃ§Ã£o: TTL curto)

**Estimativa:** 1 semana
**Impacto:** ğŸŸ¡ MÃ©dio (performance, custo)

#### 5. Expandir Base de Documentos

**Problema:** Apenas 4 leis, cobertura limitada

**Proposta:**

**Fase 1 - Leis Fundamentais** (prioritÃ¡rio):
- [ ] Lei 8.666/1993 (lei antiga de licitaÃ§Ãµes)
- [ ] Lei 12.527/2011 (Lei de Acesso Ã  InformaÃ§Ã£o)
- [ ] Lei 12.846/2013 (Lei AnticorrupÃ§Ã£o)
- [ ] Decreto 9.507/2018 (TerceirizaÃ§Ã£o)

**Fase 2 - InstruÃ§Ãµes Normativas**:
- [ ] IN SEGES 01/2019 (ContrataÃ§Ãµes de TI)
- [ ] IN SEGES 05/2017 (Gerenciamento de contratos)
- [ ] IN SLTI 01/2010 (Sustentabilidade)

**Fase 3 - JurisprudÃªncia**:
- [ ] SÃºmulas do TCU
- [ ] AcÃ³rdÃ£os relevantes do TCU
- [ ] DecisÃµes do STF sobre licitaÃ§Ãµes

**Processo:**
1. Coletar PDFs oficiais
2. Processar com `get_v1_data.ipynb`
3. Reindexar com `get_vectorial_bank_v1.ipynb`
4. Testar qualidade das respostas
5. Documentar no README

**Estimativa:** 1-2 semanas por fase
**Impacto:** ğŸŸ¡ Alto (cobertura)

#### 6. Melhorar Tratamento de Erros

**Problema:** Erros nÃ£o sÃ£o tratados gracefully

**Proposta:**
```python
from functools import wraps
import traceback

def handle_errors(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except ValueError as e:
            logger.error("Validation error", extra={"error": str(e)})
            return {"error": "Pergunta invÃ¡lida", "details": str(e)}
        except Exception as e:
            logger.error("Unexpected error", extra={
                "error": str(e),
                "traceback": traceback.format_exc()
            })
            return {"error": "Erro interno do servidor", "support_id": generate_support_id()}
    return wrapper

@handle_errors
def consultar_base_rag(pergunta: str) -> str:
    if not pergunta or len(pergunta) < 5:
        raise ValueError("Pergunta muito curta")

    # ... resto do cÃ³digo
```

**Mensagens amigÃ¡veis:**
- âŒ "Exception: object of type 'NoneType' has no len()"
- âœ… "Por favor, forneÃ§a uma pergunta com pelo menos 5 caracteres."

**Estimativa:** 1 semana
**Impacto:** ğŸŸ¡ MÃ©dio (UX, manutenibilidade)

#### 7. Otimizar Performance

**Proposta:**

**A. Cache de Embeddings** (query repetidas)
```python
embedding_cache = {}

def embed_query_cached(query: str):
    if query in embedding_cache:
        return embedding_cache[query]

    embedding = modelo_embedding.embed_query(query)
    embedding_cache[query] = embedding
    return embedding
```

**B. Batch Processing** (mÃºltiplas queries)
```python
def process_batch(queries: List[str]) -> List[str]:
    # Processar todas embeddings de uma vez
    embeddings = modelo_embedding.embed_documents(queries)

    # Buscar FAISS em paralelo
    results = [vector_db.similarity_search(emb, k=12) for emb in embeddings]

    # Invocar LLM em paralelo (async)
    respostas = await asyncio.gather(*[
        llm.ainvoke(prompt) for prompt in prompts
    ])

    return respostas
```

**C. GPU para Embeddings** (se disponÃ­vel)
```python
# Usar faiss-gpu ao invÃ©s de faiss-cpu
pip uninstall faiss-cpu
pip install faiss-gpu

# Modelo de embeddings na GPU
modelo_embedding = HuggingFaceEmbeddings(
    model_name="...",
    model_kwargs={'device': 'cuda'}
)
```

**Ganhos esperados:**
- Cache embeddings: 20-30% mais rÃ¡pido
- Batch: 2-3x throughput
- GPU: 5-10x mais rÃ¡pido (embeddings)

**Estimativa:** 1-2 semanas
**Impacto:** ğŸŸ¡ MÃ©dio (performance)

### ğŸŸ¢ Prioridade Baixa (Nice to Have)

#### 8. Frontend Customizado

**Problema:** ADK Web Ã© bÃ¡sico, pouco customizÃ¡vel

**Proposta:**
- **Framework:** React ou Streamlit
- **Features:**
  - Chat interface melhorada
  - FormataÃ§Ã£o de respostas (Markdown, highlight)
  - HistÃ³rico persistido (banco de dados)
  - Export de conversas (PDF, DOCX)
  - Feedback (ğŸ‘/ğŸ‘)
  - Analytics (dashboard de uso)

**Mockup (conceitual):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AMLDO - Assistente de LicitaÃ§Ãµes            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ” Pesquisar legislaÃ§Ã£o...               â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ‘¤ VocÃª:                                 â”‚ â”‚
â”‚ â”‚ Qual o limite de dispensa para obras?    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ¤– AMLDO:                                â”‚ â”‚
â”‚ â”‚ Segundo o **Art. 75, I da Lei 14.133**:  â”‚ â”‚
â”‚ â”‚ R$ 50.000,00                             â”‚ â”‚
â”‚ â”‚                                          â”‚ â”‚
â”‚ â”‚ [Ver fonte] [Copiar] [ğŸ‘] [ğŸ‘]          â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Digite sua pergunta...         [Enviar] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                              â”‚
â”‚ [HistÃ³rico] [ConfiguraÃ§Ãµes] [Exportar]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Estimativa:** 3-4 semanas
**Impacto:** ğŸŸ¢ MÃ©dio (UX)

#### 9. Sistema de Feedback

**Proposta:**
- BotÃµes ğŸ‘/ğŸ‘ em cada resposta
- Campo de comentÃ¡rio opcional
- Armazenar em banco de dados
- Dashboard de analytics

**Uso:**
- Identificar perguntas com baixa satisfaÃ§Ã£o
- Melhorar prompts/retrieval
- Monitorar qualidade ao longo do tempo

**ImplementaÃ§Ã£o:**
```python
# Banco de dados (SQLite)
import sqlite3

conn = sqlite3.connect('feedback.db')
cursor = conn.cursor()

cursor.execute('''
CREATE TABLE IF NOT EXISTS feedback (
    id INTEGER PRIMARY KEY,
    query TEXT,
    response TEXT,
    rating INTEGER,  -- 1 (ğŸ‘) ou -1 (ğŸ‘)
    comment TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
)
''')

def salvar_feedback(query, response, rating, comment=None):
    cursor.execute(
        'INSERT INTO feedback (query, response, rating, comment) VALUES (?, ?, ?, ?)',
        (query, response, rating, comment)
    )
    conn.commit()
```

**Estimativa:** 1 semana
**Impacto:** ğŸŸ¢ MÃ©dio (dados para melhoria)

#### 10. MÃºltiplos Idiomas

**Proposta:**
- Interface em inglÃªs
- Perguntas em inglÃªs (busca mantÃ©m em PT)
- Respostas em inglÃªs (traduÃ§Ã£o automÃ¡tica)

**Desafios:**
- Embeddings multilÃ­ngues jÃ¡ suportam inglÃªs
- Mas documentos estÃ£o em portuguÃªs
- TraduÃ§Ã£o de respostas pode perder precisÃ£o legal

**Abordagem:**
1. UsuÃ¡rio pergunta em inglÃªs
2. Sistema traduz para portuguÃªs (Google Translate API)
3. Busca no FAISS (em portuguÃªs)
4. LLM responde em portuguÃªs
5. Sistema traduz resposta para inglÃªs

**Estimativa:** 2 semanas
**Impacto:** ğŸŸ¢ Baixo (mercado internacional limitado)

## Roadmap

### Q1 2025 (Jan-Mar) - FundaÃ§Ãµes

**Objetivo:** Preparar para produÃ§Ã£o

- [x] âœ… DocumentaÃ§Ã£o completa (vocÃª estÃ¡ aqui!)
- [ ] ğŸ”´ Implementar testes automatizados
- [ ] ğŸ”´ Adicionar logging estruturado
- [ ] ğŸ”´ Implementar autenticaÃ§Ã£o bÃ¡sica
- [ ] ğŸŸ¡ Adicionar 10 novos documentos (leis fundamentais)
- [ ] ğŸŸ¡ Deploy em servidor (staging)

**EntregÃ¡vel:** Sistema testado e seguro em staging

### Q2 2025 (Abr-Jun) - OtimizaÃ§Ã£o

**Objetivo:** Melhorar performance e qualidade

- [ ] ğŸŸ¡ Cache de respostas (Redis)
- [ ] ğŸŸ¡ OtimizaÃ§Ãµes de performance (GPU, batch)
- [ ] ğŸŸ¡ Expandir documentos (instruÃ§Ãµes normativas)
- [ ] ğŸŸ¢ Frontend customizado (MVP)
- [ ] ğŸŸ¢ Sistema de feedback
- [ ] ğŸ”´ Deploy em produÃ§Ã£o

**EntregÃ¡vel:** Sistema em produÃ§Ã£o com >100 usuÃ¡rios

### Q3 2025 (Jul-Set) - ExpansÃ£o

**Objetivo:** Agregar novas fontes e funcionalidades

- [ ] ğŸŸ¡ JurisprudÃªncia (TCU, STF)
- [ ] ğŸŸ¢ Analytics e dashboard
- [ ] ğŸŸ¢ Export de conversas
- [ ] ğŸŸ¡ API pÃºblica (para integraÃ§Ãµes)
- [ ] ğŸŸ¡ Melhorias baseadas em feedback de usuÃ¡rios

**EntregÃ¡vel:** Plataforma completa com 50+ documentos

### Q4 2025 (Out-Dez) - InteligÃªncia

**Objetivo:** Features avanÃ§adas de IA

- [ ] ğŸ’¡ RAG multi-hop (perguntas complexas em mÃºltiplas etapas)
- [ ] ğŸ’¡ SummarizaÃ§Ã£o de documentos
- [ ] ğŸ’¡ ComparaÃ§Ã£o automÃ¡tica de leis (o que mudou?)
- [ ] ğŸ’¡ Alertas de atualizaÃ§Ãµes legais
- [ ] ğŸ’¡ Fine-tuning de LLM especÃ­fico do domÃ­nio

**EntregÃ¡vel:** Sistema inteligente com features diferenciadas

## Ideias Futuras

### ğŸ’¡ VisÃ£o de Longo Prazo (2026+)

#### 1. AMLDO Mobile

**Conceito:** App iOS/Android para consultas em mobilidade

**Use Case:** Gestor em reuniÃ£o precisa consultar lei rapidamente

#### 2. IntegraÃ§Ã£o com Sistemas de LicitaÃ§Ã£o

**Conceito:** Plugin para sistemas como Comprasnet, Licita JÃ¡

**Fluxo:**
- UsuÃ¡rio editando edital no sistema
- Clica em "Consultar AMLDO"
- Pergunta sobre dÃºvida especÃ­fica
- Recebe resposta sem sair do sistema

#### 3. Assistente Proativo

**Conceito:** Sistema analisa edital e sugere melhorias

**Fluxo:**
- UsuÃ¡rio faz upload de edital (PDF)
- AMLDO analisa e identifica:
  - ClÃ¡usulas que podem violar a lei
  - Prazos incorretos
  - Requisitos faltantes
- Sugere correÃ§Ãµes com fundamentaÃ§Ã£o legal

#### 4. RAG Multi-Modal

**Conceito:** Incluir imagens, grÃ¡ficos, fluxogramas

**Exemplo:**
- UsuÃ¡rio pergunta: "Como Ã© o fluxo de pregÃ£o eletrÃ´nico?"
- Sistema retorna: Texto + Fluxograma visual

#### 5. Comunidade e Crowdsourcing

**Conceito:** UsuÃ¡rios podem:
- Sugerir novos documentos
- Avaliar qualidade de respostas
- Adicionar comentÃ¡rios/anotaÃ§Ãµes
- Compartilhar interpretaÃ§Ãµes

#### 6. AMLDO Tutor (E-learning)

**Conceito:** Modo de ensino interativo

**Fluxo:**
- UsuÃ¡rio: "Quero aprender sobre pregÃ£o eletrÃ´nico"
- AMLDO: "Ã“timo! Vamos comeÃ§ar pelo bÃ¡sico. O que Ã© um pregÃ£o?"
- UsuÃ¡rio responde
- AMLDO valida e explica
- Quizzes e exercÃ­cios prÃ¡ticos

## CritÃ©rios de PriorizaÃ§Ã£o

### Framework: RICE Score

Cada feature Ã© avaliada em 4 dimensÃµes:

**R - Reach (Alcance)**: Quantos usuÃ¡rios impacta?
- 1 = <10%, 2 = 10-50%, 3 = >50%

**I - Impact (Impacto)**: Qual o valor gerado?
- 1 = baixo, 2 = mÃ©dio, 3 = alto

**C - Confidence (ConfianÃ§a)**: QuÃ£o certos estamos?
- 1 = <50%, 2 = 50-80%, 3 = >80%

**E - Effort (EsforÃ§o)**: Quanto tempo/recursos?
- 1 = <1 semana, 2 = 1-4 semanas, 3 = >1 mÃªs

**Score = (R Ã— I Ã— C) / E**

Quanto maior o score, maior a prioridade.

### Exemplos de Score:

| Feature | R | I | C | E | Score | Prioridade |
|---------|---|---|---|---|-------|------------|
| Testes automatizados | 3 | 3 | 3 | 2 | **13.5** | ğŸ”´ Alta |
| Logging estruturado | 3 | 3 | 3 | 1 | **27** | ğŸ”´ Alta |
| AutenticaÃ§Ã£o | 3 | 3 | 3 | 2 | **13.5** | ğŸ”´ Alta |
| Cache de respostas | 2 | 2 | 3 | 1 | **12** | ğŸŸ¡ MÃ©dia |
| Expandir docs | 3 | 3 | 3 | 2 | **13.5** | ğŸŸ¡ MÃ©dia |
| Frontend custom | 2 | 2 | 2 | 3 | **2.7** | ğŸŸ¢ Baixa |
| MÃºltiplos idiomas | 1 | 1 | 2 | 2 | **1** | ğŸŸ¢ Baixa |

---

**ConclusÃ£o:** DocumentaÃ§Ã£o completa! ğŸ‰

**PrÃ³ximo:** [Voltar ao Ãndice](README.md)
